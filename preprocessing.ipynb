{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Katkı Sağlayanlar:\n",
    "Emirhan Esim\n",
    "Esma Kaya\n",
    "Berkay Özçelik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "from skimage import io\n",
    "from skimage import color\n",
    "from skimage import transform\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from numpy import ndarray\n",
    "from sklearn.model_selection import train_test_split \n",
    "import torch.utils.data as data_utils\n",
    "import torchvision\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8727</th>\n",
       "      <td>99812-1-2-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>159.522205</td>\n",
       "      <td>163.522205</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8728</th>\n",
       "      <td>99812-1-3-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>181.142431</td>\n",
       "      <td>183.284976</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729</th>\n",
       "      <td>99812-1-4-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>242.691902</td>\n",
       "      <td>246.197885</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8730</th>\n",
       "      <td>99812-1-5-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>253.209850</td>\n",
       "      <td>255.741948</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>99812-1-6-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>332.289233</td>\n",
       "      <td>334.821332</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name   fsID       start         end  salience  fold  classID  \\\n",
       "8727  99812-1-2-0.wav  99812  159.522205  163.522205         2     7        1   \n",
       "8728  99812-1-3-0.wav  99812  181.142431  183.284976         2     7        1   \n",
       "8729  99812-1-4-0.wav  99812  242.691902  246.197885         2     7        1   \n",
       "8730  99812-1-5-0.wav  99812  253.209850  255.741948         2     7        1   \n",
       "8731  99812-1-6-0.wav  99812  332.289233  334.821332         2     7        1   \n",
       "\n",
       "         class  \n",
       "8727  car_horn  \n",
       "8728  car_horn  \n",
       "8729  car_horn  \n",
       "8730  car_horn  \n",
       "8731  car_horn  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#veri bilgilerinin bulunduğu csv dosyasını okuma\n",
    "csv_path = r\"C:\\Users\\emirh\\Desktop\\ai_hub_proje\\data\\UrbanSound8K\\metadata\\UrbanSound8K.csv\"\n",
    "csv_data = pd.read_csv(csv_path)\n",
    "csv_data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#görüntünün veri yolunu input olarak alır ve sırasıyla;\n",
    "#grayscale dönüşümü, resizing, normalization, [görüntü, etiket] formatına yazma\n",
    "#işlemlerini yapar.\n",
    "#[görüntü,etiket] formatında DataFrame'i oluşturur ve csv dosyası olarak kaydını yapar \n",
    "\n",
    "\n",
    "def preprocessor(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for foldername in os.listdir(directory): #spectrograms klasöründeki classID pathlerini döndür\n",
    "        f = os.path.join(directory, foldername) #classID klasörlerinin pathleri\n",
    "        for imagename in os.listdir(f):\n",
    "            imagepath = os.path.join(f, imagename)\n",
    "            rgb_img = io.imread(imagepath)[:,:,:3]\n",
    "            gray_img = color.rgb2gray(rgb_img)\n",
    "            gray_img_resized = transform.resize(gray_img, (128,128)) #grayscaled fotoğraf\n",
    "            image = np.array(gray_img_resized, 'float32')\n",
    "            image = (image-image.mean())/image.std()\n",
    "            label = int(foldername)    \n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r'C:\\Users\\emirh\\Desktop\\ai_hub_proje\\data\\spectrograms'\n",
    "\n",
    "images, labels = preprocessor(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8732, 8732)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.6713247 , -0.28672266, -1.8196371 , ..., -1.8227298 ,\n",
       "        -1.8227298 , -1.8227298 ],\n",
       "       [ 3.677114  , -0.27035457, -1.8173009 , ..., -1.8204195 ,\n",
       "        -1.8204175 , -1.8204162 ],\n",
       "       [ 3.6771352 , -0.27029043, -1.8172846 , ..., -1.8203738 ,\n",
       "        -1.8129799 , -1.8074372 ],\n",
       "       ...,\n",
       "       [ 3.6768723 , -0.20892416, -0.86748713, ...,  1.884726  ,\n",
       "         1.6924425 ,  0.9927972 ],\n",
       "       [ 3.7136507 ,  1.0344989 ,  0.2612872 , ...,  0.9487419 ,\n",
       "         0.8893153 ,  0.67563593],\n",
       "       [ 3.8196363 ,  3.7934604 ,  3.7889116 , ...,  3.7891667 ,\n",
       "         3.7891512 ,  3.7890959 ]], dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.6713247 , -0.28672266, -1.8196371 , ..., -1.8227298 ,\n",
       "        -1.8227298 , -1.8227298 ],\n",
       "       [ 3.677114  , -0.27035457, -1.8173009 , ..., -1.8204195 ,\n",
       "        -1.8204175 , -1.8204162 ],\n",
       "       [ 3.6771352 , -0.27029043, -1.8172846 , ..., -1.8203738 ,\n",
       "        -1.8129799 , -1.8074372 ],\n",
       "       ...,\n",
       "       [ 3.6768723 , -0.20892416, -0.86748713, ...,  1.884726  ,\n",
       "         1.6924425 ,  0.9927972 ],\n",
       "       [ 3.7136507 ,  1.0344989 ,  0.2612872 , ...,  0.9487419 ,\n",
       "         0.8893153 ,  0.67563593],\n",
       "       [ 3.8196363 ,  3.7934604 ,  3.7889116 , ...,  3.7891667 ,\n",
       "         3.7891512 ,  3.7890959 ]], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train ve test verilerini bölme\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7422 7422\n",
      "1310 1310\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(y_train))\n",
    "print(len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation verisi eldesi\n",
    "X_val = X_train[6112:]\n",
    "y_val = y_train[6112:]\n",
    "X_train = X_train[:6112]\n",
    "y_train = y_train[:6112]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " X_train: 6112, y_train: 6112 \n",
      " X_val: 1310, y_val: 1310 \n",
      " X_test: 1310, y_test: 1310 \n"
     ]
    }
   ],
   "source": [
    "print(f\" X_train: {len(X_train)}, y_train: {len(y_train)} \")\n",
    "print(f\" X_val: {len(X_val)}, y_val: {len(y_val)} \")\n",
    "print(f\" X_test: {len(X_test)}, y_test: {len(y_test)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy array çevrimi\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "X_val_np = np.array(X_val)\n",
    "y_train_np = np.array(y_train)\n",
    "y_test_np = np.array(y_test)\n",
    "y_val_np = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6112, 128, 128)\n",
      "(1310, 128, 128)\n",
      "(1310, 128, 128)\n",
      "(6112,)\n",
      "(1310,)\n",
      "(1310,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_np.shape)\n",
    "print(X_test_np.shape)\n",
    "print(X_val_np.shape)\n",
    "print(y_train_np.shape)\n",
    "print(y_test_np.shape)\n",
    "print(y_val_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy arrayler tensora çevriliyor\n",
    "X_train_t = torch.from_numpy(X_train_np).unsqueeze(-1).permute(0,3,1,2)\n",
    "X_test_t = torch.from_numpy(X_test_np).unsqueeze(-1).permute(0,3,1,2)\n",
    "X_val_t = torch.from_numpy(X_val_np).unsqueeze(-1).permute(0,3,1,2)\n",
    "y_train_t = torch.from_numpy(y_train_np)\n",
    "y_test_t = torch.from_numpy(y_test_np)\n",
    "y_val_t = torch.from_numpy(y_val_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6112, 1, 128, 128]),\n",
       " torch.Size([1310, 1, 128, 128]),\n",
       " torch.Size([1310, 1, 128, 128]))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_t.shape, X_test_t.shape, X_val_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6112]), torch.Size([1310]), torch.Size([1310]))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train_t.shape, y_test_t.shape, y_val_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorleri klasöre kayıt etme\n",
    "os.chdir(r\"C:\\Users\\emirh\\Desktop\\ai_hub_proje\\tensors\")\n",
    "torch.save(X_train_t, 'X_train_t.pt')\n",
    "torch.save(X_test_t, 'X_test_t.pt')\n",
    "torch.save(X_val_t, 'X_val_t.pt')\n",
    "torch.save(y_train_t, 'y_train_t.pt')\n",
    "torch.save(y_test_t, 'y_test_t.pt')\n",
    "torch.save(y_val_t, 'y_val_t.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02f0e89a1197599f3dc7c16f0e4f47d78f3d8e79d75528e8a24eade9b59b02bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

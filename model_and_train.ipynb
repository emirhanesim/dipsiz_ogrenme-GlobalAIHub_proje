{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import torch.utils.data as data_utils\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from numpy import ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#önişlemede kaydedilen tensörleri indirme\n",
    "os.chdir(r\"C:\\Users\\emirh\\Desktop\\ai_hub_proje\\tensors\")\n",
    "X_train_t = torch.load('X_train_t.pt')\n",
    "X_test_t = torch.load('X_test_t.pt')\n",
    "X_val_t = torch.load('X_val_t.pt')\n",
    "y_train_t = torch.load('y_train_t.pt')\n",
    "y_test_t = torch.load('y_test_t.pt')\n",
    "y_val_t = torch.load('y_val_t.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6112, 1, 128, 128]),\n",
       " torch.Size([1310, 1, 128, 128]),\n",
       " torch.Size([1310, 1, 128, 128]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_t.shape, X_test_t.shape, X_val_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6112]), torch.Size([1310]), torch.Size([1310]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_t.shape, y_test_t.shape, y_val_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_utils.TensorDataset(X_train_t, y_train_t)\n",
    "train_loader = data_utils.DataLoader(train, batch_size=128, shuffle=True)\n",
    "test = data_utils.TensorDataset(X_test_t, y_test_t)\n",
    "test_loader = data_utils.DataLoader(test, batch_size=128, shuffle=True)\n",
    "val = data_utils.TensorDataset(X_val_t, y_val_t)\n",
    "val_loader = data_utils.DataLoader(val, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN modelini tanımlama\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=2)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=2)\n",
    "        self.fc1 = nn.Linear(in_features=128*9*9, out_features=10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "net = Net()\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss function ve optimizer tanımla\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \t\t Training Loss: 2.1180793220798173 \t\t Validation Loss: 5.32173059203408\n",
      "Validation Loss Decreased(inf--->58.539037) \t Saving The Model\n",
      "Epoch 2 \t\t Training Loss: 2.0253326346476874 \t\t Validation Loss: 5.871380242434415\n",
      "Epoch 3 \t\t Training Loss: 1.9979338000218074 \t\t Validation Loss: 5.5802223899147725\n",
      "Epoch 4 \t\t Training Loss: 1.963235671321551 \t\t Validation Loss: 5.315732522444292\n",
      "Validation Loss Decreased(58.539037--->58.473058) \t Saving The Model\n",
      "Epoch 5 \t\t Training Loss: 1.940329981346925 \t\t Validation Loss: 5.2422614531083545\n",
      "Validation Loss Decreased(58.473058--->57.664876) \t Saving The Model\n",
      "Epoch 6 \t\t Training Loss: 1.9235815902551014 \t\t Validation Loss: 5.440058599818837\n",
      "Epoch 7 \t\t Training Loss: 1.9072921176751454 \t\t Validation Loss: 5.4482456770810215\n",
      "Epoch 8 \t\t Training Loss: 1.904681958258152 \t\t Validation Loss: 4.956360080025413\n",
      "Validation Loss Decreased(57.664876--->54.519961) \t Saving The Model\n",
      "Epoch 9 \t\t Training Loss: 1.8854498689373334 \t\t Validation Loss: 5.570773211392489\n",
      "Epoch 10 \t\t Training Loss: 1.8763023217519124 \t\t Validation Loss: 5.385674780065363\n",
      "Epoch 11 \t\t Training Loss: 1.868695929646492 \t\t Validation Loss: 5.137033354152333\n",
      "Epoch 12 \t\t Training Loss: 1.8607192263007164 \t\t Validation Loss: 5.0135886669158936\n",
      "Epoch 13 \t\t Training Loss: 1.840973714987437 \t\t Validation Loss: 5.135425979440862\n",
      "Epoch 14 \t\t Training Loss: 1.8215038379033406 \t\t Validation Loss: 4.799823760986328\n",
      "Validation Loss Decreased(54.519961--->52.798061) \t Saving The Model\n",
      "Epoch 15 \t\t Training Loss: 1.8052892262736957 \t\t Validation Loss: 5.284978151321411\n",
      "Epoch 16 \t\t Training Loss: 1.7895996049046516 \t\t Validation Loss: 4.726322780955922\n",
      "Validation Loss Decreased(52.798061--->51.989551) \t Saving The Model\n",
      "Epoch 17 \t\t Training Loss: 1.7795111338297527 \t\t Validation Loss: 4.783675237135454\n",
      "Epoch 18 \t\t Training Loss: 1.7686370710531871 \t\t Validation Loss: 4.79345440864563\n",
      "Epoch 19 \t\t Training Loss: 1.7529504174987476 \t\t Validation Loss: 5.4040890390222724\n",
      "Epoch 20 \t\t Training Loss: 1.716390959918499 \t\t Validation Loss: 4.1942924802953545\n",
      "Validation Loss Decreased(51.989551--->46.137217) \t Saving The Model\n",
      "Epoch 21 \t\t Training Loss: 1.69027233372132 \t\t Validation Loss: 4.580196033824574\n",
      "Epoch 22 \t\t Training Loss: 1.668878714243571 \t\t Validation Loss: 4.965207143263384\n",
      "Epoch 23 \t\t Training Loss: 1.6587507451574008 \t\t Validation Loss: 4.865003715861928\n",
      "Epoch 24 \t\t Training Loss: 1.6487644910812378 \t\t Validation Loss: 4.829343015497381\n",
      "Epoch 25 \t\t Training Loss: 1.6463967363039653 \t\t Validation Loss: 4.704448960044167\n",
      "Epoch 26 \t\t Training Loss: 1.63247033705314 \t\t Validation Loss: 4.89421703598716\n",
      "Epoch 27 \t\t Training Loss: 1.6253706912199657 \t\t Validation Loss: 4.610098275271329\n",
      "Epoch 28 \t\t Training Loss: 1.630607396364212 \t\t Validation Loss: 4.6238227324052295\n",
      "Epoch 29 \t\t Training Loss: 1.6240924273928006 \t\t Validation Loss: 4.6466520699587734\n",
      "Epoch 30 \t\t Training Loss: 1.6186577528715134 \t\t Validation Loss: 4.259086522189054\n",
      "Epoch 31 \t\t Training Loss: 1.6144670074184735 \t\t Validation Loss: 4.951683933084661\n",
      "Epoch 32 \t\t Training Loss: 1.6119579325119655 \t\t Validation Loss: 4.420587041161277\n",
      "Epoch 33 \t\t Training Loss: 1.6156105597813923 \t\t Validation Loss: 4.709720069711858\n",
      "Epoch 34 \t\t Training Loss: 1.6114676346381505 \t\t Validation Loss: 4.526291110298851\n",
      "Epoch 35 \t\t Training Loss: 1.605030432343483 \t\t Validation Loss: 4.5267839865251025\n",
      "Epoch 36 \t\t Training Loss: 1.6020396550496419 \t\t Validation Loss: 4.524769241159612\n",
      "Epoch 37 \t\t Training Loss: 1.6000040471553802 \t\t Validation Loss: 4.606004086407748\n",
      "Epoch 38 \t\t Training Loss: 1.6015567978223164 \t\t Validation Loss: 4.63766715743325\n",
      "Epoch 39 \t\t Training Loss: 1.6009475563963254 \t\t Validation Loss: 4.968710270794955\n",
      "Epoch 40 \t\t Training Loss: 1.6023082459966342 \t\t Validation Loss: 4.674563624642112\n",
      "Epoch 41 \t\t Training Loss: 1.6005571633577347 \t\t Validation Loss: 4.432211897589943\n",
      "Epoch 42 \t\t Training Loss: 1.6017879446347554 \t\t Validation Loss: 4.754103964025324\n",
      "Epoch 43 \t\t Training Loss: 1.6021119380990665 \t\t Validation Loss: 4.4316982139240615\n",
      "Epoch 44 \t\t Training Loss: 1.598103828728199 \t\t Validation Loss: 4.612961899150502\n",
      "Epoch 45 \t\t Training Loss: 1.5954264104366302 \t\t Validation Loss: 4.707012176513672\n",
      "Epoch 46 \t\t Training Loss: 1.5933482175072033 \t\t Validation Loss: 4.4782278754494405\n",
      "Epoch 47 \t\t Training Loss: 1.5998336672782898 \t\t Validation Loss: 4.777665138244629\n",
      "Epoch 48 \t\t Training Loss: 1.6005624681711197 \t\t Validation Loss: 4.880964647639882\n",
      "Epoch 49 \t\t Training Loss: 1.594596805671851 \t\t Validation Loss: 4.342996098778465\n",
      "Epoch 50 \t\t Training Loss: 1.5929396450519562 \t\t Validation Loss: 4.447413357821378\n",
      "Epoch 51 \t\t Training Loss: 1.5936669011910756 \t\t Validation Loss: 4.166024273092097\n",
      "Validation Loss Decreased(46.137217--->45.826267) \t Saving The Model\n",
      "Epoch 52 \t\t Training Loss: 1.592411977549394 \t\t Validation Loss: 4.8513875224373555\n",
      "Epoch 53 \t\t Training Loss: 1.5918967425823212 \t\t Validation Loss: 4.612570134076205\n",
      "Epoch 54 \t\t Training Loss: 1.5917687267065048 \t\t Validation Loss: 4.3765175342559814\n",
      "Epoch 55 \t\t Training Loss: 1.5907098824779193 \t\t Validation Loss: 4.634383158250288\n",
      "Epoch 56 \t\t Training Loss: 1.5930139223734539 \t\t Validation Loss: 5.137392282485962\n",
      "Epoch 57 \t\t Training Loss: 1.5958671395977337 \t\t Validation Loss: 4.426377686587247\n",
      "Epoch 58 \t\t Training Loss: 1.5946130429704983 \t\t Validation Loss: 4.636063359000466\n",
      "Epoch 59 \t\t Training Loss: 1.5916156396269798 \t\t Validation Loss: 4.430091489445079\n",
      "Epoch 60 \t\t Training Loss: 1.5917566219965618 \t\t Validation Loss: 4.426581859588623\n",
      "Epoch 61 \t\t Training Loss: 1.5836130405465763 \t\t Validation Loss: 4.317508935928345\n",
      "Epoch 62 \t\t Training Loss: 1.5606494297583897 \t\t Validation Loss: 4.259251031008634\n",
      "Epoch 63 \t\t Training Loss: 1.5574940666556358 \t\t Validation Loss: 4.548450058156794\n",
      "Epoch 64 \t\t Training Loss: 1.557550425330798 \t\t Validation Loss: 4.82853120023554\n",
      "Epoch 65 \t\t Training Loss: 1.5537551095088322 \t\t Validation Loss: 4.690837968479503\n",
      "Epoch 66 \t\t Training Loss: 1.5528343295057614 \t\t Validation Loss: 4.80079098181291\n",
      "Epoch 67 \t\t Training Loss: 1.5505691766738892 \t\t Validation Loss: 4.6211489764126865\n",
      "Epoch 68 \t\t Training Loss: 1.5577479551235835 \t\t Validation Loss: 4.7924393957311455\n",
      "Epoch 69 \t\t Training Loss: 1.553121988972028 \t\t Validation Loss: 4.7069383751262315\n",
      "Epoch 70 \t\t Training Loss: 1.5599838122725487 \t\t Validation Loss: 4.379405541853472\n",
      "Epoch 71 \t\t Training Loss: 1.5561902225017548 \t\t Validation Loss: 4.3050218712199815\n",
      "Epoch 72 \t\t Training Loss: 1.5545451914270718 \t\t Validation Loss: 4.528340643102473\n",
      "Epoch 73 \t\t Training Loss: 1.5523628517985344 \t\t Validation Loss: 4.794246391816572\n",
      "Epoch 74 \t\t Training Loss: 1.551485116283099 \t\t Validation Loss: 4.247962019660256\n",
      "Epoch 75 \t\t Training Loss: 1.5487348188956578 \t\t Validation Loss: 4.437844861637462\n",
      "Epoch 76 \t\t Training Loss: 1.551152765750885 \t\t Validation Loss: 4.568997729908336\n",
      "Epoch 77 \t\t Training Loss: 1.5574514443675678 \t\t Validation Loss: 4.526335000991821\n",
      "Epoch 78 \t\t Training Loss: 1.555348036189874 \t\t Validation Loss: 4.452131444757635\n",
      "Epoch 79 \t\t Training Loss: 1.554655594130357 \t\t Validation Loss: 4.5450473915446885\n",
      "Epoch 80 \t\t Training Loss: 1.5497965961694717 \t\t Validation Loss: 4.442028132351962\n",
      "Epoch 81 \t\t Training Loss: 1.5524157881736755 \t\t Validation Loss: 4.695127552205866\n",
      "Epoch 82 \t\t Training Loss: 1.5528560330470402 \t\t Validation Loss: 4.0791733698411425\n",
      "Validation Loss Decreased(45.826267--->44.870907) \t Saving The Model\n",
      "Epoch 83 \t\t Training Loss: 1.550583394865195 \t\t Validation Loss: 4.617975841869008\n",
      "Epoch 84 \t\t Training Loss: 1.5490974163015683 \t\t Validation Loss: 4.621281623840332\n",
      "Epoch 85 \t\t Training Loss: 1.5466589728991191 \t\t Validation Loss: 4.043846238743175\n",
      "Validation Loss Decreased(44.870907--->44.482309) \t Saving The Model\n",
      "Epoch 86 \t\t Training Loss: 1.553779236972332 \t\t Validation Loss: 4.353534416718916\n",
      "Epoch 87 \t\t Training Loss: 1.5477988595763843 \t\t Validation Loss: 4.564126838337291\n",
      "Epoch 88 \t\t Training Loss: 1.5501926988363266 \t\t Validation Loss: 4.439830346540972\n",
      "Epoch 89 \t\t Training Loss: 1.5493126685420673 \t\t Validation Loss: 4.6187073534185235\n",
      "Epoch 90 \t\t Training Loss: 1.5486611699064572 \t\t Validation Loss: 4.50806899504228\n",
      "Epoch 91 \t\t Training Loss: 1.549448197086652 \t\t Validation Loss: 4.627489718523893\n",
      "Epoch 92 \t\t Training Loss: 1.5510235627492268 \t\t Validation Loss: 4.455757466229525\n",
      "Epoch 93 \t\t Training Loss: 1.545781172811985 \t\t Validation Loss: 4.414394877173684\n",
      "Epoch 94 \t\t Training Loss: 1.5486581102013588 \t\t Validation Loss: 4.42713358185508\n",
      "Epoch 95 \t\t Training Loss: 1.5509560505549114 \t\t Validation Loss: 5.170935175635598\n",
      "Epoch 96 \t\t Training Loss: 1.54352152099212 \t\t Validation Loss: 4.621320962905884\n",
      "Epoch 97 \t\t Training Loss: 1.5469065755605698 \t\t Validation Loss: 4.368396130475131\n",
      "Epoch 98 \t\t Training Loss: 1.5451942433913548 \t\t Validation Loss: 4.350715983997691\n",
      "Epoch 99 \t\t Training Loss: 1.5450898980100949 \t\t Validation Loss: 4.523304267363115\n",
      "Epoch 100 \t\t Training Loss: 1.5480699067314465 \t\t Validation Loss: 4.706244577061046\n",
      "Epoch 101 \t\t Training Loss: 1.5438967272639275 \t\t Validation Loss: 4.264530918814919\n",
      "Epoch 102 \t\t Training Loss: 1.545266571144263 \t\t Validation Loss: 4.7992001880298965\n",
      "Epoch 103 \t\t Training Loss: 1.54304455469052 \t\t Validation Loss: 4.605204625563188\n",
      "Epoch 104 \t\t Training Loss: 1.5424535870552063 \t\t Validation Loss: 4.5822228084911\n",
      "Epoch 105 \t\t Training Loss: 1.5424095292886097 \t\t Validation Loss: 4.171617247841575\n",
      "Epoch 106 \t\t Training Loss: 1.5426208848754566 \t\t Validation Loss: 4.8029305718161845\n",
      "Epoch 107 \t\t Training Loss: 1.544454425573349 \t\t Validation Loss: 4.322019598700783\n",
      "Epoch 108 \t\t Training Loss: 1.5503172427415848 \t\t Validation Loss: 4.8485258492556484\n",
      "Epoch 109 \t\t Training Loss: 1.5417617112398148 \t\t Validation Loss: 4.08134709705006\n",
      "Epoch 110 \t\t Training Loss: 1.5407457103331883 \t\t Validation Loss: 4.530537778680975\n",
      "Epoch 111 \t\t Training Loss: 1.5418016562859218 \t\t Validation Loss: 4.350174340334806\n",
      "Epoch 112 \t\t Training Loss: 1.5396918281912804 \t\t Validation Loss: 4.429911375045776\n",
      "Epoch 113 \t\t Training Loss: 1.5389310469230015 \t\t Validation Loss: 4.17221025987105\n",
      "Epoch 114 \t\t Training Loss: 1.538743995130062 \t\t Validation Loss: 4.3484135107560595\n",
      "Epoch 115 \t\t Training Loss: 1.5390651946266491 \t\t Validation Loss: 4.461726600473577\n",
      "Epoch 116 \t\t Training Loss: 1.5388594915469487 \t\t Validation Loss: 4.59519852291454\n",
      "Epoch 117 \t\t Training Loss: 1.5385633731881778 \t\t Validation Loss: 4.510155916213989\n",
      "Epoch 118 \t\t Training Loss: 1.5388744647304218 \t\t Validation Loss: 4.72140604799444\n",
      "Epoch 119 \t\t Training Loss: 1.5384897713859875 \t\t Validation Loss: 4.439261718229814\n",
      "Epoch 120 \t\t Training Loss: 1.5388019531965256 \t\t Validation Loss: 4.432938857512041\n",
      "Epoch 121 \t\t Training Loss: 1.5391227180759113 \t\t Validation Loss: 4.530762434005737\n",
      "Epoch 122 \t\t Training Loss: 1.5394675731658936 \t\t Validation Loss: 4.348532828417691\n",
      "Epoch 123 \t\t Training Loss: 1.540547641615073 \t\t Validation Loss: 4.264174266295\n",
      "Epoch 124 \t\t Training Loss: 1.548982433974743 \t\t Validation Loss: 4.621765721927989\n",
      "Epoch 125 \t\t Training Loss: 1.5482953836520512 \t\t Validation Loss: 4.6433963558890605\n",
      "Epoch 126 \t\t Training Loss: 1.5474888309836388 \t\t Validation Loss: 4.3676675449718125\n",
      "Epoch 127 \t\t Training Loss: 1.5483039418856304 \t\t Validation Loss: 4.570098248395053\n",
      "Epoch 128 \t\t Training Loss: 1.5449327404300373 \t\t Validation Loss: 4.439241235906428\n",
      "Epoch 129 \t\t Training Loss: 1.545968346297741 \t\t Validation Loss: 4.351153265346181\n",
      "Epoch 130 \t\t Training Loss: 1.5530417462189992 \t\t Validation Loss: 4.52222618189725\n",
      "Epoch 131 \t\t Training Loss: 1.548565352956454 \t\t Validation Loss: 4.613218090750954\n",
      "Epoch 132 \t\t Training Loss: 1.546697127322356 \t\t Validation Loss: 4.620196710933339\n",
      "Epoch 133 \t\t Training Loss: 1.5474422524372737 \t\t Validation Loss: 4.971153519370339\n",
      "Epoch 134 \t\t Training Loss: 1.5454730937878292 \t\t Validation Loss: 4.4218901070681484\n",
      "Epoch 135 \t\t Training Loss: 1.5462046166261036 \t\t Validation Loss: 4.773648977279663\n",
      "Epoch 136 \t\t Training Loss: 1.547278533379237 \t\t Validation Loss: 4.175577813928777\n",
      "Epoch 137 \t\t Training Loss: 1.5434219017624855 \t\t Validation Loss: 4.345360018990257\n",
      "Epoch 138 \t\t Training Loss: 1.5522958065072696 \t\t Validation Loss: 4.074694243344394\n",
      "Epoch 139 \t\t Training Loss: 1.5438551381230354 \t\t Validation Loss: 4.681311087174849\n",
      "Epoch 140 \t\t Training Loss: 1.549192726612091 \t\t Validation Loss: 4.668500856919722\n",
      "Epoch 141 \t\t Training Loss: 1.5441193108757336 \t\t Validation Loss: 4.712156490846113\n",
      "Epoch 142 \t\t Training Loss: 1.5439480692148209 \t\t Validation Loss: 4.349454207853838\n",
      "Epoch 143 \t\t Training Loss: 1.5427176877856255 \t\t Validation Loss: 4.621270569888028\n",
      "Epoch 144 \t\t Training Loss: 1.5396733433008194 \t\t Validation Loss: 4.257881316271695\n",
      "Epoch 145 \t\t Training Loss: 1.539023034274578 \t\t Validation Loss: 4.720702171325684\n",
      "Epoch 146 \t\t Training Loss: 1.5386443883180618 \t\t Validation Loss: 4.521399736404419\n",
      "Epoch 147 \t\t Training Loss: 1.5382752592364948 \t\t Validation Loss: 4.53041130846197\n",
      "Epoch 148 \t\t Training Loss: 1.5378442878524463 \t\t Validation Loss: 4.259932799772783\n",
      "Epoch 149 \t\t Training Loss: 1.5385489488641422 \t\t Validation Loss: 4.519332322207364\n",
      "Epoch 150 \t\t Training Loss: 1.53854717562596 \t\t Validation Loss: 4.166787971149791\n",
      "Epoch 151 \t\t Training Loss: 1.5372619479894638 \t\t Validation Loss: 4.51608115976507\n",
      "Epoch 152 \t\t Training Loss: 1.5372169415156047 \t\t Validation Loss: 4.712464375929399\n",
      "Epoch 153 \t\t Training Loss: 1.537725920478503 \t\t Validation Loss: 4.792640967802568\n",
      "Epoch 154 \t\t Training Loss: 1.5457773382465045 \t\t Validation Loss: 4.497374946420843\n",
      "Epoch 155 \t\t Training Loss: 1.5425324117143948 \t\t Validation Loss: 4.349600835279985\n",
      "Epoch 156 \t\t Training Loss: 1.5398733640710514 \t\t Validation Loss: 4.167651805010709\n",
      "Epoch 157 \t\t Training Loss: 1.5403448417782784 \t\t Validation Loss: 4.470977132970637\n",
      "Epoch 158 \t\t Training Loss: 1.5464352344473202 \t\t Validation Loss: 4.6213577010414815\n",
      "Epoch 159 \t\t Training Loss: 1.5416676203409831 \t\t Validation Loss: 4.438965537331321\n",
      "Epoch 160 \t\t Training Loss: 1.542582020163536 \t\t Validation Loss: 4.530568339607933\n",
      "Epoch 161 \t\t Training Loss: 1.5409631878137589 \t\t Validation Loss: 4.542489051818848\n",
      "Epoch 162 \t\t Training Loss: 1.540625775853793 \t\t Validation Loss: 4.433154734698209\n",
      "Epoch 163 \t\t Training Loss: 1.5492568587263424 \t\t Validation Loss: 4.373317089947787\n",
      "Epoch 164 \t\t Training Loss: 1.5549579833944638 \t\t Validation Loss: 4.5044452493841\n",
      "Epoch 165 \t\t Training Loss: 1.5503028308351834 \t\t Validation Loss: 4.794220707633278\n",
      "Epoch 166 \t\t Training Loss: 1.545086162785689 \t\t Validation Loss: 4.3440423228523946\n",
      "Epoch 167 \t\t Training Loss: 1.5436487669746082 \t\t Validation Loss: 4.166628989306363\n",
      "Epoch 168 \t\t Training Loss: 1.5404272973537445 \t\t Validation Loss: 4.528143947774714\n",
      "Epoch 169 \t\t Training Loss: 1.5418297400077183 \t\t Validation Loss: 4.53210483897816\n",
      "Epoch 170 \t\t Training Loss: 1.5413336803515751 \t\t Validation Loss: 4.257914153012362\n",
      "Epoch 171 \t\t Training Loss: 1.5427436456084251 \t\t Validation Loss: 4.166819832541726\n",
      "Epoch 172 \t\t Training Loss: 1.5434854875008266 \t\t Validation Loss: 4.721557877280495\n",
      "Epoch 173 \t\t Training Loss: 1.5428524737556775 \t\t Validation Loss: 4.43948279727589\n",
      "Epoch 174 \t\t Training Loss: 1.5432025815049808 \t\t Validation Loss: 4.439500678669322\n",
      "Epoch 175 \t\t Training Loss: 1.539717622101307 \t\t Validation Loss: 4.941099123521284\n",
      "Epoch 176 \t\t Training Loss: 1.5392906442284584 \t\t Validation Loss: 4.43937973542647\n",
      "Epoch 177 \t\t Training Loss: 1.5434832250078518 \t\t Validation Loss: 4.389731233770197\n",
      "Epoch 178 \t\t Training Loss: 1.5377137685815494 \t\t Validation Loss: 4.75333571434021\n",
      "Epoch 179 \t\t Training Loss: 1.5410937095681827 \t\t Validation Loss: 4.6213225884871045\n",
      "Epoch 180 \t\t Training Loss: 1.5394394397735596 \t\t Validation Loss: 4.439468492161144\n",
      "Epoch 181 \t\t Training Loss: 1.5391255617141724 \t\t Validation Loss: 4.62823521007191\n",
      "Epoch 182 \t\t Training Loss: 1.5390125488241513 \t\t Validation Loss: 4.530389525673606\n",
      "Epoch 183 \t\t Training Loss: 1.542202278971672 \t\t Validation Loss: 4.348593625155362\n",
      "Epoch 184 \t\t Training Loss: 1.5414884239435196 \t\t Validation Loss: 4.32155045596036\n",
      "Epoch 185 \t\t Training Loss: 1.5396543964743614 \t\t Validation Loss: 4.527465755289251\n",
      "Epoch 186 \t\t Training Loss: 1.5459480409820874 \t\t Validation Loss: 4.5299155061895195\n",
      "Epoch 187 \t\t Training Loss: 1.5433479274312656 \t\t Validation Loss: 4.535907398570668\n",
      "Epoch 188 \t\t Training Loss: 1.54219634582599 \t\t Validation Loss: 4.800638827410611\n",
      "Epoch 189 \t\t Training Loss: 1.5423970098296802 \t\t Validation Loss: 4.4395364414561875\n",
      "Epoch 190 \t\t Training Loss: 1.547482505440712 \t\t Validation Loss: 4.2576891725713555\n",
      "Epoch 191 \t\t Training Loss: 1.546090508500735 \t\t Validation Loss: 4.257683645595204\n",
      "Epoch 192 \t\t Training Loss: 1.541760432223479 \t\t Validation Loss: 4.439414847980846\n",
      "Epoch 193 \t\t Training Loss: 1.5407635966936748 \t\t Validation Loss: 4.723121686415239\n",
      "Epoch 194 \t\t Training Loss: 1.557629217704137 \t\t Validation Loss: 4.465585405176336\n",
      "Epoch 195 \t\t Training Loss: 1.5450067470471065 \t\t Validation Loss: 4.530404806137085\n",
      "Epoch 196 \t\t Training Loss: 1.5394722769657772 \t\t Validation Loss: 4.257683970711448\n",
      "Epoch 197 \t\t Training Loss: 1.541998768846194 \t\t Validation Loss: 4.528924226760864\n",
      "Epoch 198 \t\t Training Loss: 1.5390973016619682 \t\t Validation Loss: 4.348103674975309\n",
      "Epoch 199 \t\t Training Loss: 1.5370771984259288 \t\t Validation Loss: 4.616359038786455\n",
      "Epoch 200 \t\t Training Loss: 1.537288638452689 \t\t Validation Loss: 4.256296049464833\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "min_valid_loss = np.inf\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "for e in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    net.train()     # Optional when not using Model Specific layer\n",
    "    for data, labels in train_loader:\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        if torch.cuda.is_available():\n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        target = net(data)\n",
    "        loss = criterion(target,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss_list.append(train_loss/len(train_loader))\n",
    "    \n",
    "    valid_loss = 0.0\n",
    "    net.eval()     # Optional when not using Model Specific layer\n",
    "    for data, labels in val_loader:\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        if torch.cuda.is_available():\n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "        \n",
    "        target = net(data)\n",
    "        loss = criterion(target,labels)\n",
    "        valid_loss = loss.item() * data.size(0)\n",
    "    val_loss_list.append(valid_loss/len(val_loader))\n",
    "    print(f'Epoch {e+1} \\t\\t Training Loss: {train_loss / len(train_loader)} \\t\\t Validation Loss: {valid_loss / len(val_loader)}')\n",
    "    if min_valid_loss > valid_loss:\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "        min_valid_loss = valid_loss\n",
    "        # net'i kaydet\n",
    "        torch.save(net.state_dict(), 'saved_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:  air_conditioner // engine_idling // siren // engine_idling // gun_shot // air_conditioner // air_conditioner // dog_bark // jackhammer // drilling\n"
     ]
    }
   ],
   "source": [
    "#modelin test edilmesi için sample aldık\n",
    "classes = [\"air_conditioner\", \"car_horn\", \"children_playing\", \"dog_bark\", \"drilling\", \"engine_idling\", \"gun_shot\", \"jackhammer\", \"siren\", \"street_music\"]\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "print('GroundTruth: ', ' // '.join(f'{classes[labels[j]]:5s}' for j in range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = r\"C:\\Users\\emirh\\Desktop\\ai_hub_proje\\tensors\\saved_model.pth\"\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  air_conditioner // engine_idling // siren // engine_idling // gun_shot // air_conditioner // jackhammer // dog_bark // jackhammer // drilling\n"
     ]
    }
   ],
   "source": [
    "#modeli test ediyoruz\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' // '.join(f'{classes[predicted[j]]:5s}' for j in range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: air_conditioner is 84.5 %\n",
      "Accuracy for class: car_horn is 0.0 %\n",
      "Accuracy for class: children_playing is 69.1 %\n",
      "Accuracy for class: dog_bark is 83.1 %\n",
      "Accuracy for class: drilling is 85.9 %\n",
      "Accuracy for class: engine_idling is 94.4 %\n",
      "Accuracy for class: gun_shot is 94.8 %\n",
      "Accuracy for class: jackhammer is 90.9 %\n",
      "Accuracy for class: siren is 89.4 %\n",
      "Accuracy for class: street_music is 90.6 %\n"
     ]
    }
   ],
   "source": [
    "# her sınıf için accuracy hesaplama\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 200\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loss_list), len(val_loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train ve validation loss grafikleri\n",
    "x = list(range(0,200))\n",
    "plt.plot(x, train_loss_list, label=\"train_loss\")\n",
    "plt.plot(x, val_loss_list, label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02f0e89a1197599f3dc7c16f0e4f47d78f3d8e79d75528e8a24eade9b59b02bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
